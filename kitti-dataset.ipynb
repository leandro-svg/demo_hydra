{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KITTI Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pykitti\n",
    "\n",
    "# Change this to the directory where you store KITTI data\n",
    "basedir = 'data'\n",
    "\n",
    "def load_dataset(date, drive, calibrated=False, frame_range=None):\n",
    "    \"\"\"\n",
    "    Loads the dataset with `date` and `drive`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    date        : Dataset creation date.\n",
    "    drive       : Dataset drive.\n",
    "    calibrated  : Flag indicating if we need to parse calibration data. Defaults to `False`.\n",
    "    frame_range : Range of frames. Defaults to `None`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Loaded dataset of type `raw`.\n",
    "    \"\"\"\n",
    "    dataset = pykitti.raw(basedir, date, drive)\n",
    "\n",
    "    # Load the data\n",
    "    if calibrated:\n",
    "        dataset.load_calib()  # Calibration data are accessible as named tuples\n",
    "\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    print('\\nDrive: ' + str(dataset.drive))\n",
    "    print('\\nFrame range: ' + str(dataset.frames))\n",
    "\n",
    "    if calibrated:\n",
    "        print('\\nIMU-to-Velodyne transformation:\\n' + str(dataset.calib.T_velo_imu))\n",
    "        print('\\nGray stereo pair baseline [m]: ' + str(dataset.calib.b_gray))\n",
    "        print('\\nRGB stereo pair baseline [m]: ' + str(dataset.calib.b_rgb))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from source import parseTrackletXML as xmlParser\n",
    "\n",
    "def load_tracklets_for_frames(n_frames, xml_path):\n",
    "    \"\"\"\n",
    "    Loads dataset labels also referred to as tracklets, saving them individually for each frame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_frames    : Number of frames in the dataset.\n",
    "    xml_path    : Path to the tracklets XML.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple of dictionaries with integer keys corresponding to absolute frame numbers and arrays as values. First array\n",
    "    contains coordinates of bounding box vertices for each object in the frame, and the second array contains objects\n",
    "    types as strings.\n",
    "    \"\"\"\n",
    "    tracklets = xmlParser.parseXML(xml_path)\n",
    "\n",
    "    frame_tracklets = {}\n",
    "    frame_tracklets_types = {}\n",
    "    for i in range(n_frames):\n",
    "        frame_tracklets[i] = []\n",
    "        frame_tracklets_types[i] = []\n",
    "\n",
    "    # loop over tracklets\n",
    "    for i, tracklet in enumerate(tracklets):\n",
    "        # this part is inspired by kitti object development kit matlab code: computeBox3D\n",
    "        h, w, l = tracklet.size\n",
    "        # in velodyne coordinates around zero point and without orientation yet\n",
    "        trackletBox = np.array([\n",
    "            [-l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2],\n",
    "            [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2],\n",
    "            [0.0, 0.0, 0.0, 0.0, h, h, h, h]\n",
    "        ])\n",
    "        # loop over all data in tracklet\n",
    "        for translation, rotation, state, occlusion, truncation, amtOcclusion, amtBorders, absoluteFrameNumber in tracklet:\n",
    "            # determine if object is in the image; otherwise continue\n",
    "            if truncation not in (xmlParser.TRUNC_IN_IMAGE, xmlParser.TRUNC_TRUNCATED):\n",
    "                continue\n",
    "            # re-create 3D bounding box in velodyne coordinate system\n",
    "            yaw = rotation[2]  # other rotations are supposedly 0\n",
    "            assert np.abs(rotation[:2]).sum() == 0, 'object rotations other than yaw given!'\n",
    "            rotMat = np.array([\n",
    "                [np.cos(yaw), -np.sin(yaw), 0.0],\n",
    "                [np.sin(yaw), np.cos(yaw), 0.0],\n",
    "                [0.0, 0.0, 1.0]\n",
    "            ])\n",
    "            cornerPosInVelo = np.dot(rotMat, trackletBox) + np.tile(translation, (8, 1)).T\n",
    "            frame_tracklets[absoluteFrameNumber] = frame_tracklets[absoluteFrameNumber] + [cornerPosInVelo]\n",
    "            frame_tracklets_types[absoluteFrameNumber] = frame_tracklets_types[absoluteFrameNumber] + [\n",
    "                tracklet.objectType]\n",
    "\n",
    "    return (frame_tracklets, frame_tracklets_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset downloaded from [KITTI website](http://www.cvlibs.net/datasets/kitti/raw_data.php). \n",
    "\n",
    "[2011_09_26_drive_0001 (0.4 GB)](http://kitti.is.tue.mpg.de/kitti/raw_data/2011_09_26_drive_0001/2011_09_26_drive_0001_sync.zip)\n",
    "\n",
    "* **Length**: 114 frames (00:11 minutes)\n",
    "* **Image resolution**: `1392 x 512` pixels\n",
    "* **Labels**: 12 Cars, 0 Vans, 0 Trucks, 0 Pedestrians, 0 Sitters, 2 Cyclists, 1 Trams, 0 Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "date = '2011_09_26'\n",
    "drive = '0048'\n",
    "dataset = load_dataset(date, drive)\n",
    "tracklet_rects, tracklet_types = load_tracklets_for_frames(len(list(dataset.velo)), 'data/{}/{}_drive_{}_sync/tracklet_labels.xml'.format(date, date, drive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the points distributions, we could catch something meaningful if we limit **X**, **Y** and **Z** axis to some magic numbers.\n",
    "\n",
    "Additionally we will only visualise 20% of the point cloud, as each frame contains ~120K points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "colors = {\n",
    "    'Car': 'b',\n",
    "    'Tram': 'r',\n",
    "    'Cyclist': 'g',\n",
    "    'Van': 'c',\n",
    "    'Truck': 'm',\n",
    "    'Pedestrian': 'y',\n",
    "    'Sitter': 'k'\n",
    "}\n",
    "axes_limits = [\n",
    "    [-20, 80], # X axis range\n",
    "    [-20, 20], # Y axis range\n",
    "    [-3, 10]   # Z axis range\n",
    "]\n",
    "axes_str = ['X', 'Y', 'Z']\n",
    "\n",
    "def draw_box(pyplot_axis, vertices, axes=[0, 1, 2], color='black'):\n",
    "    \"\"\"\n",
    "    Draws a bounding 3D box in a pyplot axis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pyplot_axis : Pyplot axis to draw in.\n",
    "    vertices    : Array 8 box vertices containing x, y, z coordinates.\n",
    "    axes        : Axes to use. Defaults to `[0, 1, 2]`, e.g. x, y and z axes.\n",
    "    color       : Drawing color. Defaults to `black`.\n",
    "    \"\"\"\n",
    "    vertices = vertices[axes, :]\n",
    "    connections = [\n",
    "        [0, 1], [1, 2], [2, 3], [3, 0],  # Lower plane parallel to Z=0 plane\n",
    "        [4, 5], [5, 6], [6, 7], [7, 4],  # Upper plane parallel to Z=0 plane\n",
    "        [0, 4], [1, 5], [2, 6], [3, 7]  # Connections between upper and lower planes\n",
    "    ]\n",
    "    for connection in connections:\n",
    "        pyplot_axis.plot(*vertices[:, connection], c=color, lw=0.5)\n",
    "\n",
    "def display_frame_statistics(dataset, tracklet_rects, tracklet_types, frame, points=0.2):\n",
    "    \"\"\"\n",
    "    Displays statistics for a single frame. Draws camera data, 3D plot of the lidar point cloud data and point cloud\n",
    "    projections to various planes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset         : `raw` dataset.\n",
    "    tracklet_rects  : Dictionary with tracklet bounding boxes coordinates.\n",
    "    tracklet_types  : Dictionary with tracklet types.\n",
    "    frame           : Absolute number of the frame.\n",
    "    points          : Fraction of lidar points to use. Defaults to `0.2`, e.g. 20%.\n",
    "    \"\"\"\n",
    "    dataset_gray = list(dataset.gray)\n",
    "    dataset_rgb = list(dataset.rgb)\n",
    "    dataset_velo = list(dataset.velo)\n",
    "    \n",
    "    print('Frame timestamp: ' + str(dataset.timestamps[frame]))\n",
    "    # Draw camera data\n",
    "    f, ax = plt.subplots(2, 2, figsize=(15, 5))\n",
    "    ax[0, 0].imshow(dataset_gray[frame][0], cmap='gray')\n",
    "    ax[0, 0].set_title('Left Gray Image (cam0)')\n",
    "    ax[0, 1].imshow(dataset_gray[frame][1], cmap='gray')\n",
    "    ax[0, 1].set_title('Right Gray Image (cam1)')\n",
    "    ax[1, 0].imshow(dataset_rgb[frame][0])\n",
    "    ax[1, 0].set_title('Left RGB Image (cam2)')\n",
    "    ax[1, 1].imshow(dataset_rgb[frame][1])\n",
    "    ax[1, 1].set_title('Right RGB Image (cam3)')\n",
    "    plt.show()\n",
    "\n",
    "    points_step = int(1. / points)\n",
    "    point_size = 0.01 * (1. / points)\n",
    "    velo_range = range(0, dataset_velo[frame].shape[0], points_step)\n",
    "    velo_frame = dataset_velo[frame][velo_range, :]      \n",
    "    def draw_point_cloud(ax, title, axes=[0, 1, 2], xlim3d=None, ylim3d=None, zlim3d=None):\n",
    "        \"\"\"\n",
    "        Convenient method for drawing various point cloud projections as a part of frame statistics.\n",
    "        \"\"\"\n",
    "        ax.scatter(*np.transpose(velo_frame[:, axes]), s=point_size, c=velo_frame[:, 3], cmap='gray')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('{} axis'.format(axes_str[axes[0]]))\n",
    "        ax.set_ylabel('{} axis'.format(axes_str[axes[1]]))\n",
    "        if len(axes) > 2:\n",
    "            ax.set_xlim3d(*axes_limits[axes[0]])\n",
    "            ax.set_ylim3d(*axes_limits[axes[1]])\n",
    "            ax.set_zlim3d(*axes_limits[axes[2]])\n",
    "            ax.set_zlabel('{} axis'.format(axes_str[axes[2]]))\n",
    "        else:\n",
    "            ax.set_xlim(*axes_limits[axes[0]])\n",
    "            ax.set_ylim(*axes_limits[axes[1]])\n",
    "        # User specified limits\n",
    "        if xlim3d!=None:\n",
    "            ax.set_xlim3d(xlim3d)\n",
    "        if ylim3d!=None:\n",
    "            ax.set_ylim3d(ylim3d)\n",
    "        if zlim3d!=None:\n",
    "            ax.set_zlim3d(zlim3d)\n",
    "            \n",
    "        for t_rects, t_type in zip(tracklet_rects[frame], tracklet_types[frame]):\n",
    "            draw_box(ax, t_rects, axes=axes, color=colors[t_type])\n",
    "            \n",
    "    # Draw point cloud data as 3D plot\n",
    "    f2 = plt.figure(figsize=(15, 8))\n",
    "    ax2 = f2.add_subplot(111, projection='3d')                    \n",
    "    draw_point_cloud(ax2, 'Velodyne scan', xlim3d=(-10,30))\n",
    "    plt.show()\n",
    "    \n",
    "    # Draw point cloud data as plane projections\n",
    "    f, ax3 = plt.subplots(3, 1, figsize=(15, 25))\n",
    "    draw_point_cloud(\n",
    "        ax3[0], \n",
    "        'Velodyne scan, XZ projection (Y = 0), the car is moving in direction left to right', \n",
    "        axes=[0, 2] # X and Z axes\n",
    "    )\n",
    "    draw_point_cloud(\n",
    "        ax3[1], \n",
    "        'Velodyne scan, XY projection (Z = 0), the car is moving in direction left to right', \n",
    "        axes=[0, 1] # X and Y axes\n",
    "    )\n",
    "    draw_point_cloud(\n",
    "        ax3[2], \n",
    "        'Velodyne scan, YZ projection (X = 0), the car is moving towards the graph plane', \n",
    "        axes=[1, 2] # Y and Z axes\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame = 10\n",
    "\n",
    "display_frame_statistics(dataset, tracklet_rects, tracklet_types, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from source.utilities import print_progress\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "def draw_3d_plot(frame, dataset, tracklet_rects, tracklet_types, points=0.2):\n",
    "    \"\"\"\n",
    "    Saves a single frame for an animation: a 3D plot of the lidar data without ticks and all frame trackelts.\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame           : Absolute number of the frame.\n",
    "    dataset         : `raw` dataset.\n",
    "    tracklet_rects  : Dictionary with tracklet bounding boxes coordinates.\n",
    "    tracklet_types  : Dictionary with tracklet types.\n",
    "    points          : Fraction of lidar points to use. Defaults to `0.2`, e.g. 20%.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Saved frame filename.\n",
    "    \"\"\"\n",
    "    dataset_velo = list(dataset.velo)\n",
    "    \n",
    "    f = plt.figure(figsize=(12, 8))\n",
    "    axis = f.add_subplot(111, projection='3d', xticks=[], yticks=[], zticks=[])\n",
    "\n",
    "    points_step = int(1. / points)\n",
    "    point_size = 0.01 * (1. / points)\n",
    "    velo_range = range(0, dataset_velo[frame].shape[0], points_step)\n",
    "    velo_frame = dataset_velo[frame][velo_range, :]\n",
    "    axis.scatter(*np.transpose(velo_frame[:, [0, 1, 2]]), s=point_size, c=velo_frame[:, 3], cmap='gray')\n",
    "    axis.set_xlim3d(*axes_limits[0])\n",
    "    axis.set_ylim3d(*axes_limits[1])\n",
    "    axis.set_zlim3d(*axes_limits[2])\n",
    "    for t_rects, t_type in zip(tracklet_rects[frame], tracklet_types[frame]):\n",
    "        draw_box(axis, t_rects, axes=[0, 1, 2], color=colors[t_type])\n",
    "    filename = 'video/frame_{0:0>4}.png'.format(frame)\n",
    "    plt.savefig(filename)\n",
    "    plt.close(f)\n",
    "    return filename\n",
    "\n",
    "frames = []\n",
    "n_frames = len(list(dataset.velo))\n",
    "\n",
    "print('Preparing animation frames...')\n",
    "for i in range(n_frames):\n",
    "    print_progress(i, n_frames - 1)\n",
    "    filename = draw_3d_plot(i, dataset, tracklet_rects, tracklet_types)\n",
    "    frames += [filename]\n",
    "print('...Animation frames ready.')\n",
    "\n",
    "clip = ImageSequenceClip(frames, fps=5)\n",
    "% time\n",
    "clip.write_gif('pcl_data.gif', fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (demo_venv_hydra)",
   "language": "python",
   "name": "demo_venv_hydra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
